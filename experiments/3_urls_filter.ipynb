{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* we do not want to crawl image/other file urls (i.e. urls that are not likely to contain html content)\n",
    "'''\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "from typing import List, Set\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class WebPageURLFilter:\n",
    "    '''\n",
    "    * filter urls that look like a file url\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # Common file extensions that typically don't contain useful text\n",
    "        self.non_webpage_extensions: Set[str] = {\n",
    "            # Images\n",
    "            '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.svg', '.ico', '.tiff', '.tif', '.pct', '.psp',\n",
    "            \n",
    "            # Documents/Downloads\n",
    "            '.pdf', '.doc', '.docx', '.ppt', '.pptx', '.xls', '.xlsx', '.csv', '.odp', '.pps', '.ods',\n",
    "            '.zip', '.rar', '.tar', '.gz', '.7z', '.7zip', '.bz2', '.tar.gz', '.xz',\n",
    "            \n",
    "            '.odt', '.pst', '.ai', '.drw', '.dxf', '.eps', '.ps', '.cdr', '.odg',\n",
    "            \n",
    "            # Audio/Video\n",
    "            '.mp3', '.wav', '.ogg', '.m4a', '.aac', '.wma', '.ra', '.mid', '.au', '.aiff', '.3gp', '.asf', '.asx',\n",
    "            '.mp4', '.avi', '.mov', '.wmv', '.flv', '.webm', '.m4v', '.mkv', '.mng', '.mpg', '.qt', '.rm', '.swf',\n",
    "            \n",
    "            # Programming/Data\n",
    "            '.js', '.css', '.json', '.rss', '.atom',    # 'xml lets exclude remove xml as they might contain sitemaps\n",
    "            '.woff', '.woff2', '.ttf', '.eot',  # Fonts\n",
    "            '.sql', '.db', '.sqlite',\n",
    "            \n",
    "            # Other binary/non-text files\n",
    "            '.exe', '.dll', '.bin', '.iso', '.dmg', '.apk', '.ipa'\n",
    "        }\n",
    "\n",
    "        \n",
    "        # API and non-webpage URL patterns\n",
    "        self.non_webpage_patterns = [\n",
    "            # API endpoints\n",
    "            r'/api/.*',\n",
    "            r'/v\\d+/.*',  # API versions\n",
    "            r'/rest/.*',\n",
    "            r'/graphql.*',\n",
    "            r'/ws/.*',    # WebSocket\n",
    "            \n",
    "            # Authentication/user management\n",
    "            r'/oauth/.*',\n",
    "            r'/login/.*',\n",
    "            r'/logout/.*',\n",
    "            r'/signin/.*',\n",
    "            r'/signup/.*',\n",
    "            \n",
    "            # Common static asset paths\n",
    "            r'/static/.*',\n",
    "            r'/assets/.*',\n",
    "            r'/dist/.*',\n",
    "            r'/build/.*',\n",
    "            r'/images/.*',\n",
    "            r'/img/.*',\n",
    "            r'/css/.*',\n",
    "            r'/js/.*',\n",
    "            r'/fonts/.*',\n",
    "            \n",
    "            # Admin/backend paths\n",
    "            r'/admin/.*',\n",
    "            r'/wp-admin/.*',\n",
    "            r'/wp-content/.*',\n",
    "            r'/wp-includes/.*',\n",
    "            r'/phpmyadmin/.*',\n",
    "            r'/cpanel/.*',\n",
    "            \n",
    "            # Common CDN patterns\n",
    "            r'cdn\\.',\n",
    "            r'\\.cloudfront\\.net',\n",
    "            r'\\.akamai\\.net',\n",
    "            \n",
    "            # Common tracking/analytics\n",
    "            r'/pixel/.*',\n",
    "            r'/tracking/.*',\n",
    "            r'/analytics/.*',\n",
    "            r'/stats/.*',\n",
    "            \n",
    "            # Feed URLs\n",
    "            r'/feed/.*',\n",
    "            r'/rss/.*',\n",
    "            r'/atom/.*',\n",
    "            \n",
    "            # Common non-webpage endpoints\n",
    "            r'/download/.*',\n",
    "            r'/uploads/.*',\n",
    "            r'/thumb/.*',\n",
    "            r'/thumbnail/.*',\n",
    "            r'/print/.*',\n",
    "            r'/raw/.*'\n",
    "        ]\n",
    "        \n",
    "        # Compile patterns for better performance\n",
    "        self.compiled_patterns = [re.compile(pattern, re.IGNORECASE) \n",
    "                                for pattern in self.non_webpage_patterns]\n",
    "\n",
    "    def is_likely_webpage(self, url: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check if a URL is likely to point to a webpage with useful text content.\n",
    "        \n",
    "        Args:\n",
    "            url: URL to check\n",
    "            \n",
    "        Returns:\n",
    "            bool: True if the URL likely points to a webpage, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Parse URL\n",
    "            parsed = urlparse(url)\n",
    "            \n",
    "            # Skip empty or invalid URLs\n",
    "            if not parsed.netloc or not parsed.scheme:\n",
    "                return False\n",
    "            \n",
    "            # Skip non-HTTP(S) protocols\n",
    "            if parsed.scheme not in ('http', 'https'):\n",
    "                return False\n",
    "            \n",
    "            # Check file extension\n",
    "            path = parsed.path.lower()\n",
    "            if any(path.endswith(ext) for ext in self.non_webpage_extensions):\n",
    "                return False\n",
    "            \n",
    "            # Check for non-webpage patterns\n",
    "            if any(pattern.search(url) for pattern in self.compiled_patterns):\n",
    "                return False\n",
    "            \n",
    "            # Additional checks for common cases\n",
    "            path_parts = path.split('/')\n",
    "            for part in path_parts:\n",
    "                # Skip URLs with numeric IDs in path (often API endpoints)\n",
    "                if part.isdigit() and len(part) > 6:\n",
    "                    return False\n",
    "                    \n",
    "                # Skip URLs with very long random-looking segments\n",
    "                if len(part) > 50:\n",
    "                    return False\n",
    "                \n",
    "                # Skip URLs with base64-looking segments\n",
    "                if len(part) > 20 and re.match(r'^[A-Za-z0-9+/]+={0,2}$', part):\n",
    "                    return False\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def filter_urls(self, urls: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Filter a list of URLs to keep only those likely to be webpages.\n",
    "        \n",
    "        Args:\n",
    "            urls: List of URLs to filter\n",
    "            \n",
    "        Returns:\n",
    "            List of URLs that are likely to be webpages\n",
    "        \"\"\"\n",
    "        return [url for url in urls if self.is_likely_webpage(url)]\n",
    "    \n",
    "    def is_same_domain(self, url1, url2):\n",
    "        return urlparse(url1).netloc == urlparse(url2).netloc\n",
    "\n",
    "\n",
    "# Test the filter\n",
    "def test_url_filter():\n",
    "    filter = WebPageURLFilter()\n",
    "    \n",
    "    test_cases = [\n",
    "        # Should be accepted (webpages)\n",
    "        (\"https://example.com/blog/article\", True),\n",
    "        (\"https://example.com/about\", True),\n",
    "        (\"https://example.com/products/shoes\", True),\n",
    "        (\"https://example.com/category/electronics\", True),\n",
    "        \n",
    "        # Should be rejected (non-webpages)\n",
    "        (\"https://example.com/image.jpg\", False),\n",
    "        (\"https://example.com/document.pdf\", False),\n",
    "        (\"https://api.example.com/v1/users\", False),\n",
    "        (\"https://example.com/static/main.css\", False),\n",
    "        (\"https://cdn.example.com/asset.js\", False),\n",
    "        (\"https://example.com/wp-admin/settings\", False),\n",
    "        (\"https://example.com/download/file.zip\", False),\n",
    "        (\"https://example.com/12345678\", False),\n",
    "        (\"https://example.com/api/data\", False),\n",
    "        (\"https://example.com/assets/logo.png\", False),\n",
    "        (\"ftp://example.com/file\", False),\n",
    "        (\"mailto:user@example.com\", False),\n",
    "        \n",
    "        # Edge cases\n",
    "        (\"https://example.com\", True),\n",
    "        (\"https://blog.example.com\", True),\n",
    "        (\"https://example.com/page-with-image.html\", True),\n",
    "        (\"https://example.com/article-123\", True),\n",
    "        (\"https://example.com/very-long-base64-looking-string-that-should-be-rejected\" + \"a\" * 50, False),\n",
    "    ]\n",
    "    \n",
    "    for url, expected in test_cases:\n",
    "        result = filter.is_likely_webpage(url)\n",
    "        assert result == expected, f\"\\nURL: {url}\\nExpected: {expected}\\nGot: {result}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_url_filter()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
