{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nepberta_urls = [\"https://ekantipur.com/\",  \"https://onlinekhabar.com/\",  \"https://nagariknews.com/\",  \"https://thahakhabar.com/\",  \"https://ratopati.com/\",  \"https://reportersnepal.com/\",  \"https://setopati.com/\",  \"https://hamrakura.com/\",  \"https://lokpath.com/\",  \"https://abhiyandaily.com/\",  \"https://pahilopost.com/\",  \"https://lokaantar.com/\",  \"https://dcnepal.com/\",  \"https://nayapage.com/\",  \"https://nayapatrikadaily.com/\",  \"https://everestdainik.com/\",  \"https://imagekhabar.com/\",  \"https://shilapatra.com/\",  \"https://khabarhub.com/\",  \"https://baahrakhari.com/\",  \"https://ujyaaloonline.com/\",  \"https://nepalkhabar.com/\",  \"https://emountaintv.com/\",  \"https://kathmandupress.com/\",  \"https://farakdhar.com/\",  \"https://kendrabindu.com/\",  \"https://dhangadhikhabar.com/\",  \"https://gorkhapatraonline.com/\",  \"https://nepalpress.com/\",  \"https://hamrokhelkud.com/\",  \"https://himalkhabar.com/\",  \"https://nepallive.com/\",  \"https://nepalsamaya.com/\",  \"https://kalakarmi.com/\",  \"https://dainiknewsnepal.com/\"]\n",
    "\n",
    "\n",
    "'''\n",
    "* 'dainikonline' seems to have been closed or moved somewhere else.\n",
    "* latest tweets in their twitter page are from 2019. https://twitter.com/dainikonline2?lang=en\n",
    "'''\n",
    "nepberta_error_urls  = [\"https://dainikonline.com/\"]    \n",
    "additional_urls = [\"https://www.dainiknepal.com/\"]\n",
    "\n",
    "crawling_completed = []\n",
    "have_crawled_incomplete = []\n",
    "\n",
    "\n",
    "need_special_attention = [\"https://www.bbc.com/nepali\", \"https://beta.gorkhapatraonline.com/epapermaincategory\", \"https://epaper.gorkhapatraonline.com/\"]\n",
    "'''\n",
    "bbc_nepali: avoid following links that does not start with: bbc.com/nepali\n",
    "gorkhapatra: it would be nice to crawl pdfs of gorkhapatra\n",
    "            problem is: i coudn't find their encoding scheme\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_file_name = \"your_file.csv\"\n",
    "\n",
    "# Sample list of dictionaries\n",
    "data_list = [\n",
    "    \n",
    "    {'key1': 4.0, 'key3': 6.0},\n",
    "    {'key1': 1.0, 'key2': 2.0, 'key3': 3.0},\n",
    "    {'key2': 7.0, 'key3': 9.0},\n",
    "]\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file_name, 'a', newline='') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Extract unique column names from dictionary keys\n",
    "    column_names = set(key for d in data_list for key in d.keys())\n",
    "\n",
    "    # Check if the CSV file already has a header\n",
    "    if not csv_file.readable():\n",
    "        # If not, write the header\n",
    "        csv_writer.writerow(column_names)\n",
    "\n",
    "    # Iterate through each dictionary and write rows to CSV\n",
    "    for d in data_list:\n",
    "        # Create a list of values for the row, using empty string for missing keys\n",
    "        row_values = [str(d.get(column, '')) for column in column_names]\n",
    "        csv_writer.writerow(row_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/anon/weekly-projects/scrapy_engine/test.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anon/weekly-projects/scrapy_engine/test.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Drop duplicate rows in csv\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anon/weekly-projects/scrapy_engine/test.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/anon/weekly-projects/scrapy_engine/test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anon/weekly-projects/scrapy_engine/test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m csv_file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39myour_file.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/anon/weekly-projects/scrapy_engine/test.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Read the CSV file into a DataFrame\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows in csv\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "csv_file_name = \"your_file.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_name)\n",
    "\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Write the cleaned DataFrame back to the CSV file\n",
    "df.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "'''\n",
    "\n",
    "'''\n",
    "import csv\n",
    "import os\n",
    "\n",
    "csv_file_name = \"your_file.csv\"\n",
    "\n",
    "# Sample list of dictionaries\n",
    "data_list = [\n",
    "    \n",
    "    {'key1': 4.0, 'key3': 6.0},{'key1': 1.0, 'key2': 2.0, 'key3': 3.0},\n",
    "    {'key2': 7.0, 'key3': 9.0},\n",
    "]\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(csv_file_name, 'a', newline='') as csv_file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Check if the CSV file is empty\n",
    "    is_empty = os.path.getsize(csv_file_name) == 0\n",
    "\n",
    "    # Extract unique column names from dictionary keys\n",
    "    column_names = set(key for d in data_list for key in d.keys())\n",
    "\n",
    "    # Write the header only if the CSV file is empty\n",
    "    if is_empty:\n",
    "        csv_writer.writerow(column_names)\n",
    "\n",
    "    # Iterate through each dictionary and write rows to CSV\n",
    "    for d in data_list:\n",
    "        # Create a list of values for the row, using empty string for missing keys\n",
    "        row_values = [str(d.get(column, '')) for column in column_names]\n",
    "        csv_writer.writerow(row_values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
