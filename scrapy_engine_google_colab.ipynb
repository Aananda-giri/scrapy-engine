{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByhX5TFCU3iR",
        "outputId": "fbac7ea6-8c10-455c-9db9-e723c5c8133d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scrapy-engine'...\n",
            "remote: Enumerating objects: 1103, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/229)\u001b[K\rremote: Counting objects:   1% (3/229)\u001b[K\rremote: Counting objects:   2% (5/229)\u001b[K\rremote: Counting objects:   3% (7/229)\u001b[K\rremote: Counting objects:   4% (10/229)\u001b[K\rremote: Counting objects:   5% (12/229)\u001b[K\rremote: Counting objects:   6% (14/229)\u001b[K\rremote: Counting objects:   7% (17/229)\u001b[K\rremote: Counting objects:   8% (19/229)\u001b[K\rremote: Counting objects:   9% (21/229)\u001b[K\rremote: Counting objects:  10% (23/229)\u001b[K\rremote: Counting objects:  11% (26/229)\u001b[K\rremote: Counting objects:  12% (28/229)\u001b[K\rremote: Counting objects:  13% (30/229)\u001b[K\rremote: Counting objects:  14% (33/229)\u001b[K\rremote: Counting objects:  15% (35/229)\u001b[K\rremote: Counting objects:  16% (37/229)\u001b[K\rremote: Counting objects:  17% (39/229)\u001b[K\rremote: Counting objects:  18% (42/229)\u001b[K\rremote: Counting objects:  19% (44/229)\u001b[K\rremote: Counting objects:  20% (46/229)\u001b[K\rremote: Counting objects:  21% (49/229)\u001b[K\rremote: Counting objects:  22% (51/229)\u001b[K\rremote: Counting objects:  23% (53/229)\u001b[K\rremote: Counting objects:  24% (55/229)\u001b[K\rremote: Counting objects:  25% (58/229)\u001b[K\rremote: Counting objects:  26% (60/229)\u001b[K\rremote: Counting objects:  27% (62/229)\u001b[K\rremote: Counting objects:  28% (65/229)\u001b[K\rremote: Counting objects:  29% (67/229)\u001b[K\rremote: Counting objects:  30% (69/229)\u001b[K\rremote: Counting objects:  31% (71/229)\u001b[K\rremote: Counting objects:  32% (74/229)\u001b[K\rremote: Counting objects:  33% (76/229)\u001b[K\rremote: Counting objects:  34% (78/229)\u001b[K\rremote: Counting objects:  35% (81/229)\u001b[K\rremote: Counting objects:  36% (83/229)\u001b[K\rremote: Counting objects:  37% (85/229)\u001b[K\rremote: Counting objects:  38% (88/229)\u001b[K\rremote: Counting objects:  39% (90/229)\u001b[K\rremote: Counting objects:  40% (92/229)\u001b[K\rremote: Counting objects:  41% (94/229)\u001b[K\rremote: Counting objects:  42% (97/229)\u001b[K\rremote: Counting objects:  43% (99/229)\u001b[K\rremote: Counting objects:  44% (101/229)\u001b[K\rremote: Counting objects:  45% (104/229)\u001b[K\rremote: Counting objects:  46% (106/229)\u001b[K\rremote: Counting objects:  47% (108/229)\u001b[K\rremote: Counting objects:  48% (110/229)\u001b[K\rremote: Counting objects:  49% (113/229)\u001b[K\rremote: Counting objects:  50% (115/229)\u001b[K\rremote: Counting objects:  51% (117/229)\u001b[K\rremote: Counting objects:  52% (120/229)\u001b[K\rremote: Counting objects:  53% (122/229)\u001b[K\rremote: Counting objects:  54% (124/229)\u001b[K\rremote: Counting objects:  55% (126/229)\u001b[K\rremote: Counting objects:  56% (129/229)\u001b[K\rremote: Counting objects:  57% (131/229)\u001b[K\rremote: Counting objects:  58% (133/229)\u001b[K\rremote: Counting objects:  59% (136/229)\u001b[K\rremote: Counting objects:  60% (138/229)\u001b[K\rremote: Counting objects:  61% (140/229)\u001b[K\rremote: Counting objects:  62% (142/229)\u001b[K\rremote: Counting objects:  63% (145/229)\u001b[K\rremote: Counting objects:  64% (147/229)\u001b[K\rremote: Counting objects:  65% (149/229)\u001b[K\rremote: Counting objects:  66% (152/229)\u001b[K\rremote: Counting objects:  67% (154/229)\u001b[K\rremote: Counting objects:  68% (156/229)\u001b[K\rremote: Counting objects:  69% (159/229)\u001b[K\rremote: Counting objects:  70% (161/229)\u001b[K\rremote: Counting objects:  71% (163/229)\u001b[K\rremote: Counting objects:  72% (165/229)\u001b[K\rremote: Counting objects:  73% (168/229)\u001b[K\rremote: Counting objects:  74% (170/229)\u001b[K\rremote: Counting objects:  75% (172/229)\u001b[K\rremote: Counting objects:  76% (175/229)\u001b[K\rremote: Counting objects:  77% (177/229)\u001b[K\rremote: Counting objects:  78% (179/229)\u001b[K\rremote: Counting objects:  79% (181/229)\u001b[K\rremote: Counting objects:  80% (184/229)\u001b[K\rremote: Counting objects:  81% (186/229)\u001b[K\rremote: Counting objects:  82% (188/229)\u001b[K\rremote: Counting objects:  83% (191/229)\u001b[K\rremote: Counting objects:  84% (193/229)\u001b[K\rremote: Counting objects:  85% (195/229)\u001b[K\rremote: Counting objects:  86% (197/229)\u001b[K\rremote: Counting objects:  87% (200/229)\u001b[K\rremote: Counting objects:  88% (202/229)\u001b[K\rremote: Counting objects:  89% (204/229)\u001b[K\rremote: Counting objects:  90% (207/229)\u001b[K\rremote: Counting objects:  91% (209/229)\u001b[K\rremote: Counting objects:  92% (211/229)\u001b[K\rremote: Counting objects:  93% (213/229)\u001b[K\rremote: Counting objects:  94% (216/229)\u001b[K\rremote: Counting objects:  95% (218/229)\u001b[K\rremote: Counting objects:  96% (220/229)\u001b[K\rremote: Counting objects:  97% (223/229)\u001b[K\rremote: Counting objects:  98% (225/229)\u001b[K\rremote: Counting objects:  99% (227/229)\u001b[K\rremote: Counting objects: 100% (229/229)\u001b[K\rremote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 1103 (delta 141), reused 141 (delta 61), pack-reused 874\u001b[K\n",
            "Receiving objects: 100% (1103/1103), 3.37 MiB | 34.83 MiB/s, done.\n",
            "Resolving deltas: 100% (597/597), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Aananda-giri/scrapy-engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9DTYme-U9AD",
        "outputId": "37e11b04-29c2-4474-cd19-c5a8b33fc3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/scrapy-engine\n"
          ]
        }
      ],
      "source": [
        "%cd scrapy-engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_4IeAztV0x0",
        "outputId": "10c5ff97-56b9-422e-9ef5-585201c3163d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at eb772f3 update requirements.txt\n",
            "From https://github.com/Aananda-giri/scrapy-engine\n",
            " * branch            v2         -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git reset --hard\n",
        "!git pull origin v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5u-7syRAhAnQ",
        "outputId": "704b03bc-b0b9-4ac4-8d02-f17158abe07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code is running in google colab\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "# import pandas as pd\n",
        "\n",
        "def load_env_var_in_google_colab():\n",
        "    # Assuming environment variables are set in google colab Secrets\n",
        "\n",
        "    if 'google.colab' in sys.modules:\n",
        "        # Code is running in google colab\n",
        "        print(\"Code is running in google colab\")\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            environ_variables = [\"REDIS_HOST\", \"REDIS_PASSWORD\", \"REDIS_PORT\", \"mongo_password\", \"mongo_username\"]\n",
        "            for env_var in environ_variables:\n",
        "                try:\n",
        "                    os.environ[env_var] = userdata.get(env_var)\n",
        "                except Exception as Ex:\n",
        "                  print(Ex)\n",
        "                  # break\n",
        "            os.environ.get(\"mongo_password\")\n",
        "        except Exception as Ex:\n",
        "                  print(Ex)\n",
        "load_env_var_in_google_colab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHbfqgtyYJoK",
        "outputId": "ece1cc80-c39a-4939-deda-1297bf1be359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXQedajhXSrP",
        "outputId": "5576768e-9934-4f66-8e6b-8620fc6f71d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-25 14:37:24 [scrapy.utils.log] INFO: Scrapy 2.7.1 started (bot: scrapy_engine)\n",
            "2024-05-25 14:37:24 [scrapy.utils.log] INFO: Versions: lxml 4.9.4.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.1, w3lib 2.1.2, Twisted 22.10.0, Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0], pyOpenSSL 24.1.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.7, Platform Linux-6.1.85+-x86_64-with-glibc2.35\n",
            "2024-05-25 14:37:24 [scrapy.crawler] INFO: Overridden settings:\n",
            "{'AUTOTHROTTLE_ENABLED': True,\n",
            " 'AUTOTHROTTLE_START_DELAY': 2,\n",
            " 'BOT_NAME': 'scrapy_engine',\n",
            " 'CONCURRENT_REQUESTS': 15,\n",
            " 'COOKIES_ENABLED': False,\n",
            " 'FEED_EXPORT_ENCODING': 'utf-8',\n",
            " 'LOG_LEVEL': 'INFO',\n",
            " 'NEWSPIDER_MODULE': 'scrapy_engine.spiders',\n",
            " 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',\n",
            " 'SPIDER_MODULES': ['scrapy_engine.spiders'],\n",
            " 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}\n",
            "2024-05-25 14:37:24 [scrapy.extensions.telnet] INFO: Telnet Password: ade57784786644a4\n",
            "2024-05-25 14:37:24 [scrapy.middleware] INFO: Enabled extensions:\n",
            "['scrapy.extensions.corestats.CoreStats',\n",
            " 'scrapy.extensions.telnet.TelnetConsole',\n",
            " 'scrapy.extensions.memusage.MemoryUsage',\n",
            " 'scrapy.extensions.feedexport.FeedExporter',\n",
            " 'scrapy.extensions.logstats.LogStats',\n",
            " 'scrapy.extensions.throttle.AutoThrottle']\n",
            "2024-05-25 14:37:24 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
            "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
            " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
            " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
            " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
            " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
            " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
            " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
            " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
            "2024-05-25 14:37:24 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
            "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
            " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
            " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
            " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
            " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
            "2024-05-25 14:37:24 [scrapy.middleware] INFO: Enabled item pipelines:\n",
            "[]\n",
            "2024-05-25 14:37:24 [scrapy.core.engine] INFO: Spider opened\n",
            "2024-05-25 14:37:25 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-05-25 14:37:25 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
            "\n",
            "\n",
            " start:['https://www.bbc.com/nepali/news-58730386', 'https://www.bbc.com/nepali/articles/c3gpnvwryg4o', 'https://www.bbc.com/nepali/news-52047275', 'https://www.bbc.com/nepali/topics/cqywjkryjnkt', 'https://www.bbc.com/nepali/news-61480284', 'https://www.bbc.com/nepali/news-57872394', 'https://www.bbc.com/nepali/news-58511405', 'https://www.bbc.com/nepali/news-56422627', 'https://www.bbc.com/nepali/news-43186761', 'https://www.bbc.com/nepali/news-56422627'] \n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/scrapy/selector/unified.py:82: UserWarning: Selector got both text and root, root is being ignored.\n",
            "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
            "2024-05-25 14:37:31 [langid.langid] INFO: initializing identifier\n",
            "2024-05-25 14:38:35 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 0 items (at 0 items/min)\n",
            "2024-05-25 14:39:26 [scrapy.extensions.logstats] INFO: Crawled 5 pages (at 2 pages/min), scraped 0 items (at 0 items/min)\n"
          ]
        }
      ],
      "source": [
        "!scrapy crawl worker_spider_v2 -o worker_spider_v2.json"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}